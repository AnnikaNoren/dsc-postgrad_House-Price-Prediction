{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Price Your Home\n",
    "## A data exploration, modeling and evaluation using the Ames, Iowa housing sales dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "- Initial exploration\n",
    "    - Exploration of the target variable\n",
    "- Data preparation\n",
    "- Modeling\n",
    "    - Model-less baseline\n",
    "    - Multiple linear regression\n",
    "    - Ridge regression\n",
    "- Discussion of next steps\n",
    "\n",
    "\n",
    "Selling a home can be a torturous process. Homeowners rely on real estate agent's opinions and experience to guide them to the right decisions. So many questions haunt the homeowner. Are you pricing it right for the market? Are you pricing it to move quickly or get the maximum price?\n",
    "\n",
    "My project aims to predict the sale price of houses using the [Ames, Iowa housing dataset](http://jse.amstat.org/v19n3/decock.pdf) produced by Dean De Cook, of Truman University in 2011. The training dataset used for this anaylsis was sourced from the [Advanced Regression Techniques Kaggle competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview). \n",
    "\n",
    "I began with a baseline that predicts only the mean house price from the training data for each house, but this model does very poorly (of course). My final model is a Ridge regression model, which had an R2 Score of 0.78 and a MAE of $24,244."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The subset of the Ames, Iowa dataset includes 1,460 home sales and record 81 variables for each home. The variables describe the details of the home, its ammenities, the lot, the zoning, and descriptors of the type of sale itself. While many variables are not within the control of the homeowner, such as lot size or zoning, including them in the eventual model will be useful for controlling for the impact. \n",
    "\n",
    "#### Data Descisions\n",
    "\n",
    "**Removed Observations**\n",
    "\n",
    "I used the variable `SaleType`, to exclude new construction and estate trasfers from the analysis. I assumed that homeowners most interested in this analysis would be currently living _in_ their home and looking to sell. I then dropped the variable. Removing those home sales reduced the dataset to 1,295 observations.\n",
    "\n",
    "\n",
    "\n",
    "**Removed Variables**\n",
    "\n",
    "- `Id` was removed, as it is a house identifier and not descriptive. \n",
    "- `FireplaceQu` was removed because the majority of houes do not have fireplaces. \n",
    "- `MiscFeature` was removed because there were so few misc features in the dataset. Sheds, second garages, and such counted as misc features.\n",
    "- All variables that assessed the quality or condition of a _specific part of the house_ were dropped. Only Overall Condition and Overall Quality were retained. I mad this choice because the Overall variables are composits of the individual. If housing condition proves to be an important variable, later analysis can examine how the quality of individual rooms interact with overall quality and impact the final sale. \n",
    "\n",
    "**Adjusted Variables**\n",
    "\n",
    "`Alley`: Only 91 homes in the dataset were listed to have `Alley`s behind the house, and the values for that variable were \"gravel\", \"paved\", or missing. I created a new variable to just capture **if** the property was adjacent to the property and drop the original alley type variable.\n",
    "\n",
    "`PoolArea` & `PoolQC`: There are only 6 pools in the dataset. I dropped `PoolQC` and transformed `PoolArea` into `HasPool`\n",
    "\n",
    "`HasFireplace`: reduced `Fireplaces`, which is a count of fireplaces in the home, to a binary yes/no if the home has a fireplace at all.\n",
    "\n",
    "`HasFence`: reduced `Fence`, a list of fence condition descriptors, to a binary yes/no if the home came with a fence.\n",
    "\n",
    "`LotFrontage`: filled the missing values with 0. The variable measures the number of feet of street the property touches. \n",
    "\n",
    "`GarageFinish`: filled missing values with `Unf`, \"unfinished\", as those are the properties that are missing garages. An interaction term with `HasGarage`, and setting `Unf` as the baseline when the variable is one hot encoded, will account for any conflicts. \n",
    "\n",
    "**New Variables**\n",
    "\n",
    "`HasGarage`: if `GarageArea` equals zero, then the property has no garage. It also explains why some observations have missing variables for garage attributes. Upon investigation, those observations have zero garage area. \n",
    "\n",
    "`GarageAreaPerCar`: `GarageArea` divided by `GarageCars`. With this created I could then drop `GarageArea`. It's assumed that the more cars, the larger the garage, so I did not want both variables in there violating regression assumptions. Having the ratio will control for multi-car garages that actually have very little space.\n",
    "\n",
    "A [full description of the variables](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data?select=data_description.txt) in the dataset is available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Custom code\n",
    "import code.data_prep_code as dpc\n",
    "\n",
    "# Visalization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Data Preparation and Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Feature importance library\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dpc.address_nas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GarageFinish    81\n",
       "GarageType      81\n",
       "GarageYrBlt     81\n",
       "BsmtFinType2    38\n",
       "BsmtExposure    38\n",
       "BsmtFinType1    37\n",
       "MasVnrType       8\n",
       "MasVnrArea       8\n",
       "Electrical       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_count = df.isna().sum().sort_values(ascending=False)\n",
    "na_count[na_count>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 68 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1460 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "Foundation       1460 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "HasAlley         1460 non-null int64\n",
      "HasPool          1460 non-null int64\n",
      "HasFence         1460 non-null int64\n",
      "HasFirePlace     1460 non-null int64\n",
      "dtypes: float64(3), int64(36), object(29)\n",
      "memory usage: 775.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring nulls and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attchd     870\n",
       "Detchd     387\n",
       "BuiltIn     88\n",
       "Basment     19\n",
       "CarPort      9\n",
       "2Types       6\n",
       "Name: GarageType, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.GarageType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unf    605\n",
       "RFn    422\n",
       "Fin    352\n",
       "Name: GarageFinish, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.GarageFinish.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_used_homes = df.loc[~df.SaleType.str.contains(\"New|COD\")].copy()\n",
    "df_used_homes.drop(columns = ['SaleType'], inplace = True)\n",
    "df_used_homes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_used_homes['HasAlley'] = 0\n",
    "df_used_homes.Alley.fillna(\"not\",inplace=True)\n",
    "df_used_homes.loc[(df_used_homes.Alley.str.contains(\"Grvl|Pave\")), 'HasAlley'] = 1\n",
    "df_used_homes.drop(columns = ['Alley'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_used_homes['HasPool'] = 0\n",
    "df_used_homes.loc[(df_used_homes.PoolArea > 0), 'HasPool'] = 1\n",
    "df_used_homes.drop(columns = ['PoolArea', 'PoolQC'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_used_homes['HasFirePlace'] = 0\n",
    "df_used_homes.loc[(df_used_homes.Fireplaces > 0), 'HasFirePlace'] = 1\n",
    "df_used_homes.drop(columns = ['Fireplaces', 'FireplaceQu'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_used_homes['HasFence'] = 0\n",
    "df_used_homes.loc[(~df_used_homes.Fence.isna()), 'HasFence'] = 1\n",
    "df_used_homes.drop(columns = ['Fence'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_used_homes.drop(columns=[\"MiscFeature\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_used_homes.LotFrontage.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_used_homes.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant = [k for k in test if ('Qual' in k or 'Cond' in k) and (\"Overall\" not in k) and (k!= \"SaleCondition\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_used_homes.drop(columns = redundant, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = df_used_homes.isna().sum().sort_values(ascending=False)\n",
    "na_count[na_count>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the breakdown of each numeric column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Target Variable\n",
    "\n",
    "The target variable shows that there are some outliers in the data, which are homes that were sold at much higher prices than most of the other homes in the dataset. I kept these outliers in, however may consider doing a transformation at some point to normalize the target variable. Alternatively, I could train my model without those outliers, with the understanding that then my model would only be accurate at homes that would be sold at prices less than a certain amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the distribution of the target variable with a boxplot\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.boxplot(x=df['SalePrice'])\n",
    "plt.title(\"Boxplot for Target Variable\")\n",
    "plt.xlabel(\"Price in Dollars\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the correlation between variables and the target using a heatmap\n",
    "plt.figure(figsize=(2,10))\n",
    "sns.heatmap(df.corr()[['SalePrice']])\n",
    "plt.title(\"Correlation of Each Independent Variable \\n with the Target Variable \\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most correlated variable with the target is `OverallQual`, which captures the ranking of the Overall Quality of a home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.groupby('OverallQual')['SalePrice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(test, test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only numeric columns\n",
    "num_cols = list(df.dtypes[df.dtypes != 'object'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subsetting my dataframe\n",
    "df_num = df[num_cols]\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_dataframe(df):\n",
    "    '''\n",
    "    Summarizes each column in a Pandas dataframe, where each row of the \n",
    "    summary output is a column of the input dataframe, df\n",
    "    Will show the datatype of data in the column, the number of missing values\n",
    "    in that column, and the number of unique values in the column\n",
    "    -\n",
    "    Input:\n",
    "    df : Pandas dataframe\n",
    "    -\n",
    "    Output:\n",
    "    summary : Pandas dataframe, now showing column details\n",
    "    '''\n",
    "    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
    "    summary = summary.reset_index()\n",
    "    summary['Name'] = summary['index'] # name of each variable \n",
    "    summary = summary[['Name','dtypes']] # data type of each variable\n",
    "    summary['Missing'] = df.isnull().sum().values # number of missing values  \n",
    "    summary['Uniques'] = df.nunique().values # number of unique values\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_dataframe(df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping the three columns with null values: \n",
    "# LotFrontage, MasVnrArea and GarageYrBlt\n",
    "df_num.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting my data into X and Y\n",
    "target = 'SalePrice'\n",
    "used_cols = list(col for col in df_num.columns.to_list() if col not in [target, 'Id'])\n",
    "\n",
    "X = df_num[used_cols]\n",
    "y = df_num[target]\n",
    "\n",
    "# Creating a split in my data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling my data\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Less Baseline\n",
    "\n",
    "I began with a baseline that predicts only the mean house price from the training data for each house, but this model does very poorly (of course). My final model is a Ridge regression model, which had an R2 Score of 0.78 and a MAE of $24,244.\n",
    "\n",
    "I began with a model-less baseline which simply predicts the average sale price from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the target mean from the training data\n",
    "y_mean_train = y_train.mean()\n",
    "\n",
    "# Creating predictions for the train and test sets\n",
    "baseline_y_pred_train = ([y_mean_train]*len(y_train))\n",
    "baseline_y_pred_test = ([y_mean_train]*len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluating my model-less baseline\n",
    "# Checking the scores on both train and test set to look for overfitting\n",
    "print(f\"Training R2: {r2_score(y_train, baseline_y_pred_train)}\")\n",
    "print(f\"Testing R2: {r2_score(y_test, baseline_y_pred_test)}\")\n",
    "print(\"---\")\n",
    "print(f\"Training MAE: {mean_absolute_error(y_train, baseline_y_pred_train)}\")\n",
    "print(f\"Testing MAE: {mean_absolute_error(y_test, baseline_y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression Model\n",
    "\n",
    "I then used a multiple linear regression model on my 33 numeric features that I already prepared and scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = lr.predict(X_train_scaled)\n",
    "y_pred_test = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training R2: {r2_score(y_train, y_pred_train)}\")\n",
    "print(f\"Testing R2: {r2_score(y_test, y_pred_test)}\")\n",
    "print(\"---\")\n",
    "print(f\"Training MAE: {mean_absolute_error(y_train, y_pred_train)}\")\n",
    "print(f\"Testing MAE: {mean_absolute_error(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression Model\n",
    "\n",
    "Looking at the correlation between variables in the test set, I can see that there is correlation between features. I thus use a Ridge regression model to attempt to regularize away from the effects of that multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the correlation between features using a heatmap\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_num[used_cols].corr())\n",
    "plt.title(\"Exploring Correlation Between Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(random_state=42)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "ridge_y_pred_train = ridge.predict(X_train_scaled)\n",
    "ridge_y_pred_test = ridge.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training R2: {r2_score(y_train, ridge_y_pred_train)}\")\n",
    "print(f\"Testing R2: {r2_score(y_test, ridge_y_pred_test)}\")\n",
    "print(\"---\")\n",
    "print(f\"Training MAE: {mean_absolute_error(y_train, ridge_y_pred_train)}\")\n",
    "print(f\"Testing MAE: {mean_absolute_error(y_test, ridge_y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Feature Importance\n",
    "\n",
    "I'm using the eli5 library to do permutation importance to explore which feature was the most important to my Ridge regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the weights, aka importance, for each variable \n",
    "perm = PermutationImportance(ridge, random_state=1).fit(X_test_scaled, y_test)\n",
    "eli5.show_weights(perm, feature_names = X_train.columns.tolist(), top=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the most important feature to my Ridge regression model is the one which is most correlated with the target: `OverallQual`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "In the future I would like to first use more of the categorical features, and perhaps encode some of the discrete features I used in my final model. I would also like to then only use the most important features, perhaps by regularizing using both LASSO and Ridge through an ElasticNet model. I could also only use the top 5-10 features based on Permutation Importance. \n",
    "\n",
    "I'd also like to explore capping my training data so that I create a model that only works on houses priced up to a certain point. This would narrow the target audience of my model, but at the same time Could make it work better on houses that are priced within a specific range. Thus, if I received a result from my model outside that range I could know that my model is likely not accurately pricing that home and thus should be handled using different techniques or models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
